{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in case of not having this package\n",
    "#! conda install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"att_faces/s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first of all we use the first 5 pictures of each class for feature extraction using PCA .\n",
    "#### In other words we use the first 5 pictures for dimentionality reduction using PCA .\n",
    "#### Note that the dataset has 40 classes with 10 pictures so it has 400 images or instance.\n",
    "#### pictures' dimensions are 1024 by 1024 so we resize them to 32 by 32 to get 1024 pixels or features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampels: 200 , attrs: 1024\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # train\n",
    "    target = []\n",
    "    X = np.array([],dtype=int)\n",
    "    for num in range(1,41):\n",
    "        #trainList = np.random.choice(range(1,11), 5, replace=False)\n",
    "        trainList = np.array([1,2,3,4,5])\n",
    "        for j in trainList:\n",
    "            file_path = join(data_folder + str(num), str(j) + \".pgm\")\n",
    "            #file_path = \"att_faces/s%d/%d.pgm\" % (num,j)\n",
    "            loaded_image=np.array(plt.imread(file_path))\n",
    "            image_32x32 = cv2.resize(loaded_image, (32, 32), interpolation=cv2.IMREAD_GRAYSCALE)\n",
    "            image_1024 = image_32x32.reshape(-1)\n",
    "            X = np.concatenate((X,image_1024),axis=0)\n",
    "            target.append(num)\n",
    "    X = np.reshape(X,(200,1024))\n",
    "    #X = X.T #? :/\n",
    "\n",
    "n ,p = np.shape(X)    \n",
    "print(\"sampels: %d , attrs: %d\" % (n,p))\n",
    "target = np.array(target)\n",
    "y = target\n",
    "print(y.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1024)\n",
      "variance of features:  [1. 1. 1. ... 1. 1. 1.]\n",
      "Covariance Matrix :\n",
      " [[200.         197.81472344 197.11249131 ... -20.80814811  10.68487359\n",
      "  -10.43091112]\n",
      " [197.81472344 200.         198.09024534 ... -25.44000651   7.11263237\n",
      "  -12.08494327]\n",
      " [197.11249131 198.09024534 200.         ... -27.89989016   7.02732701\n",
      "  -10.6697906 ]\n",
      " ...\n",
      " [-20.80814811 -25.44000651 -27.89989016 ... 200.         151.30418051\n",
      "  143.02810981]\n",
      " [ 10.68487359   7.11263237   7.02732701 ... 151.30418051 200.\n",
      "  168.16208956]\n",
      " [-10.43091112 -12.08494327 -10.6697906  ... 143.02810981 168.16208956\n",
      "  200.        ]]\n",
      "\n",
      "\n",
      "\n",
      "shape of Covariance Matrix :\n",
      " (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardized_data = StandardScaler().fit_transform(X)\n",
    "#print(scaler.fit(X))\n",
    "print(standardized_data.shape)\n",
    "print(\"variance of features: \",np.var(standardized_data,axis=0))\n",
    "sample_data = standardized_data\n",
    "#print(scaler.transform(X)) # Here we should transform test data via scaler\n",
    "R_x = np.matmul(sample_data.T, sample_data) # It should be checked\n",
    "print('Covariance Matrix :\\n',R_x)\n",
    "print('\\n\\n')\n",
    "print('shape of Covariance Matrix :\\n',R_x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Eigen Vectors : \n",
      " (1024, 5)\n",
      "Max 5 Eigen Values : \n",
      " [10352.89612334 11642.16106012 18281.96562144 27513.72134189\n",
      " 32713.03590476]\n",
      "Updated shape of Eigen Vectors : \n",
      " (1024, 5)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import eigh\n",
    "import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "eigen_values, eigen_vectors = eigh(R_x, eigvals=(1019,1023))\n",
    "\n",
    "print('Shape of Eigen Vectors : \\n',eigen_vectors.shape)\n",
    "print('Max 5 Eigen Values : \\n',eigen_values)\n",
    "\n",
    "A = eigen_vectors\n",
    "# print('5 Eigen Vectors from 5 max eigen values : \\n',eigen_vectors)\n",
    "print('Updated shape of Eigen Vectors : \\n',A.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of eigen vectors ---  shape of traversed sample_data ---  shape of new coordinates\n",
      "\n",
      "\t (1024, 5) \t,\t    (1024, 200) \t,\t (200, 5)\n",
      "\n",
      "                      ********************************************* \n",
      "\n",
      "\t\t\t (200, 1024)  x  (1024, 5)  =  (200, 5)\n",
      "\n",
      "(200, 5)\n"
     ]
    }
   ],
   "source": [
    "new_coordinates = np.matmul(sample_data,A)\n",
    "\n",
    "print()\n",
    "print( 'shape of eigen vectors ---' , ' shape of traversed sample_data ---' , ' shape of new coordinates')\n",
    "print()\n",
    "print( '\\t',A.shape,'\\t,\\t   ', sample_data.T.shape,'\\t,\\t', new_coordinates.shape)\n",
    "print('\\n',' '*20,'*'*45,'\\n')\n",
    "print('\\t\\t\\t',sample_data.shape,' x ',A.shape ,' = ', new_coordinates.shape)\n",
    "print()\n",
    "print(new_coordinates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coordinates = np.hstack((new_coordinates, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "   1st_principal  2nd_principal  3rd_principal  4th_principal  5th_principal  \\\n",
      "0       3.666213       4.484835      18.610272      -0.613120      14.128133   \n",
      "1      20.767415       0.038980      -1.646347       5.595974      24.820460   \n",
      "2       4.992645       6.813258      10.171215       7.769072      19.192764   \n",
      "3       3.412162     -21.033907       4.221059       7.767411      24.919410   \n",
      "4       4.349715     -13.928596       5.234321      11.823780      26.338073   \n",
      "5      -0.665908      -1.911835      13.325572       9.223935      -0.200505   \n",
      "6       1.872696       5.065024      14.309759       7.209565      -0.023390   \n",
      "7      -1.144515       2.307209      11.491299       9.740701       0.065005   \n",
      "8       2.460077       4.493274      13.707785       8.731214      -1.176714   \n",
      "9       5.485019       1.925007      13.252942       7.552715       0.926405   \n",
      "\n",
      "   label  \n",
      "0    1.0  \n",
      "1    1.0  \n",
      "2    1.0  \n",
      "3    1.0  \n",
      "4    1.0  \n",
      "5    2.0  \n",
      "6    2.0  \n",
      "7    2.0  \n",
      "8    2.0  \n",
      "9    2.0  \n"
     ]
    }
   ],
   "source": [
    "columns=(\"1st_principal\",\"2nd_principal\",\"3rd_principal\",\"4th_principal\",\"5th_principal\",\"label\")\n",
    "dataframe = pd.DataFrame(data=new_coordinates, columns=columns)\n",
    "print(\"*\"*80)\n",
    "print(dataframe.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "till now, we implement PCA on the first 5 images of each class.\n",
    "let's do it again and use 5 random images from each class instead to get better result.\n",
    "then we use classifier to recognize each picture's class .\n",
    "our classifier will be KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
