{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in case of not having this package\n",
    "#! conda install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"att_faces/s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first of all we use the first 5 pictures of each class for feature extraction using PCA . \\\n",
    "In other words we use the first 5 pictures for dimentionality reduction using PCA . \\\n",
    "Note that the dataset has 40 classes with 10 pictures so it has 400 images or instance. \\\n",
    "pictures' dimensions are 1024 by 1024 so we resize them to 32 by 32 to get 1024 pixels or features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (1024, 200)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # train\n",
    "    target = []\n",
    "    X = np.array([],dtype=int)\n",
    "    for num in range(1,41):\n",
    "        #trainList = np.random.choice(range(1,11), 5, replace=False)\n",
    "        trainList = np.array([1,2,3,4,5])\n",
    "        for j in trainList:\n",
    "            file_path = join(data_folder + str(num), str(j) + \".pgm\")\n",
    "            #file_path = \"att_faces/s%d/%d.pgm\" % (num,j)\n",
    "            loaded_image=np.array(plt.imread(file_path))\n",
    "            image_32x32 = cv2.resize(loaded_image, (32, 32), interpolation=cv2.IMREAD_GRAYSCALE)\n",
    "            image_1024 = image_32x32.reshape(-1)\n",
    "            X = np.concatenate((X,image_1024),axis=0)\n",
    "            target.append(num)\n",
    "    X = np.reshape(X,(200,1024))\n",
    "    X = X.T #? :/\n",
    "\n",
    "print(\"shape of X: \",np.shape(X))    \n",
    "target = np.array(target)\n",
    "y = target\n",
    "print(y.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 200)\n",
      "variance of features: \n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Covariance Matrix :\n",
      " [[ 0.52450121  0.51512422  0.51267137 ... -0.01585257  0.04468213\n",
      "  -0.02795363]\n",
      " [ 0.51512422  0.5191006   0.51370206 ... -0.0330889   0.03507535\n",
      "  -0.03385335]\n",
      " [ 0.51267137  0.51370206  0.5197142  ... -0.04723574  0.02876351\n",
      "  -0.03421926]\n",
      " ...\n",
      " [-0.01585257 -0.0330889  -0.04723574 ...  1.06607211  0.7886853\n",
      "   0.75657813]\n",
      " [ 0.04468213  0.03507535  0.02876351 ...  0.7886853   0.86861384\n",
      "   0.76825325]\n",
      " [-0.02795363 -0.03385335 -0.03421926 ...  0.75657813  0.76825325\n",
      "   0.89851417]]\n",
      "\n",
      "\n",
      " shape of Covariance Matrix :\n",
      " (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardized_data = StandardScaler().fit_transform(X)\n",
    "print(standardized_data.shape)\n",
    "print(\"variance of features: \\n\",np.var(standardized_data,axis=0))\n",
    "sample_data = standardized_data\n",
    "R_x = np.cov(sample_data)\n",
    "print('Covariance Matrix :\\n',R_x)\n",
    "print('\\n\\n shape of Covariance Matrix :\\n',R_x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.54601729794814\n",
      "Max 5 Eigen Values : \n",
      " [ 25.33769153  29.47657473  49.67106486  55.00715167 115.5460173 ]\n",
      "Shape of selsected Eigen Vectors : \n",
      " (1024, 5)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import eigh\n",
    "import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "eigen_values, eigen_vectors = eigh(R_x, eigvals=(1019,1023))\n",
    "eigen_values_all, eigen_vectors_all = eigh(R_x)\n",
    "print(np.max(eigen_values_all))\n",
    "\n",
    "\n",
    "print('Max 5 Eigen Values : \\n',eigen_values)\n",
    "\n",
    "A = eigen_vectors\n",
    "# print('5 Eigen Vectors from 5 max eigen values : \\n',eigen_vectors)\n",
    "print('Shape of selsected Eigen Vectors : \\n',A.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of eigen vectors ---  shape of traversed sample_data ---  shape of new coordinates\n",
      "\n",
      "\t (1024, 5) \t,\t    (200, 1024) \t,\t (5, 200)\n",
      "\n",
      "                      ********************************************* \n",
      "\n",
      "\t\t\t (1024, 200)  x  (1024, 5)  =  (5, 200)\n",
      "\n",
      "(5, 200)\n",
      "(5, 5)\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "Y = np.matmul(A.T,sample_data)\n",
    "\n",
    "print()\n",
    "print( 'shape of eigen vectors ---' , ' shape of traversed sample_data ---' , ' shape of new coordinates')\n",
    "print()\n",
    "print( '\\t',A.shape,'\\t,\\t   ', sample_data.T.shape,'\\t,\\t', Y.shape)\n",
    "print('\\n',' '*20,'*'*45,'\\n')\n",
    "print('\\t\\t\\t',A.shape ,' x ', sample_data.shape ,' = ', Y.shape)\n",
    "print()\n",
    "print(Y.shape)\n",
    "cov_Y = np.cov(Y)\n",
    "print(cov_Y.shape)\n",
    "print(np.count_nonzero(cov_Y - np.diag(np.diagonal(cov_Y))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 200)\n"
     ]
    }
   ],
   "source": [
    "new_coordinates = np.vstack((Y, y))\n",
    "print(new_coordinates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "   1st_principal  2nd_principal  3rd_principal  4th_principal  5th_principal  \\\n",
      "0       1.029389      15.102670     -11.683695       2.597424       0.635404   \n",
      "1       1.441480      10.376982      -1.192030       3.581704       8.833767   \n",
      "2      -4.881152      15.286837      -8.679019      -1.818384       8.001261   \n",
      "3      -5.840347       1.301226     -19.089628      -1.410391       9.847155   \n",
      "4      -2.282916       2.961842     -16.558806      -0.787762      12.097081   \n",
      "5       1.224777      12.286186     -12.076247       3.190137       6.977436   \n",
      "6       1.247818      16.535387      -8.808525       3.255922       5.254378   \n",
      "7       0.439993      14.115016     -10.462126       0.437130       7.513113   \n",
      "8       1.140402      16.166608      -8.608314       3.931531       6.294706   \n",
      "9       1.234074      15.686049      -9.183584       4.445870       5.826574   \n",
      "\n",
      "   label  \n",
      "0    1.0  \n",
      "1    1.0  \n",
      "2    1.0  \n",
      "3    1.0  \n",
      "4    1.0  \n",
      "5    2.0  \n",
      "6    2.0  \n",
      "7    2.0  \n",
      "8    2.0  \n",
      "9    2.0  \n"
     ]
    }
   ],
   "source": [
    "columns=(\"1st_principal\",\"2nd_principal\",\"3rd_principal\",\"4th_principal\",\"5th_principal\",\"label\")\n",
    "dataframe = pd.DataFrame(data=new_coordinates.T, columns=columns)\n",
    "print(\"*\"*80)\n",
    "print(dataframe.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "till now, we implement PCA on the first 5 images of each class.\n",
    "let's do it again and use 5 random images from each class instead to get better result.\n",
    "then we use classifier to recognize each picture's class .\n",
    "our classifier will be KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
